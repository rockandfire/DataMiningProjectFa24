{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from LinearRegression import SimpleLinearRegression \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically is converting this file to a class so that it's easier to deal with during gui runtime\n",
    "class MTGProject:\n",
    "    def __init__(self, upcoming_code = 'DSK'):\n",
    "\t\t#initializes the cards \n",
    "\n",
    "        #sets all cards to dataframe\n",
    "        cards = pd.read_csv('./cards.csv', low_memory=False)\n",
    "        cards = cards[cards.availability.str.contains('paper')].drop_duplicates(subset='name', keep='last')\n",
    "        cards = cards[~cards.types.str.contains('Land')]\n",
    "        cards = cards[~cards.text.isnull()]\n",
    "        cards = cards[['name', 'colorIdentity', 'keywords', 'text', 'edhrecRank', 'manaValue', 'uuid', 'availability', 'isOnlineOnly', 'isTextless', 'manaCost', 'types', 'setCode']]\n",
    "        cards['edhrecRank'] = cards['edhrecRank'].fillna(cards['edhrecRank'].max())\n",
    "\n",
    "        self.df_cards = cards\n",
    "\n",
    "        #splits the card into upcoming and current cards\n",
    "        self.df_current_cards = cards[~cards['setCode'].str.contains(upcoming_code)]\n",
    "        self.df_upcoming_cards = cards[cards['setCode'].str.contains(upcoming_code)]\n",
    "        #drops edhrec of cards\n",
    "\n",
    "        #intializes other variables for later functions\n",
    "        self.df_related_commander_cards = None\n",
    "        self.clusters = None\n",
    "        self.rule_phrases = []\n",
    "        self.df_related_cards = None\n",
    "        self.upcoming_rec_cards = None\n",
    "        self.upcoming_indices = None\n",
    "        self.linear_model = None\n",
    "        self.upcoming_cards_data = None\n",
    "\n",
    "\t#gets card info from dataset\n",
    "\t#mainly used for gui\n",
    "    def get_card(self, cardname):\n",
    "        row = self.df_cards.loc[self.df_cards['name'] == cardname].iloc[0]\n",
    "        #removes annoying \\n in the text\n",
    "        card_text = row['text']\n",
    "        card_text = card_text.replace('\\\\n', '- ')\n",
    "        #print(card_text)\n",
    "\n",
    "        card = {\n",
    "            'cardname': cardname,\n",
    "            'types': row['types'],\n",
    "            'manacost': row['manaCost'],\n",
    "            'cardtext': card_text,\n",
    "            'edhrec': row['edhrecRank'],\n",
    "            #this info is used for within class and not in gui\n",
    "            'setcode': row['setCode']\n",
    "            } \n",
    "        return card\n",
    "    \n",
    "    # Perform K-Means clustering on the set of valid \n",
    "    # cards using EDHRec Rank to determine distance\n",
    "    def k_means(self, k, cards_in_k):\n",
    "        centroids = []\n",
    "\n",
    "        edh_scores = sorted(cards_in_k['edhrecRank'].to_list())\n",
    "\n",
    "        # Maybe update to force into range of quarters of true range?\n",
    "        for i in range(k):\n",
    "            centroids.append(np.random.randint(edh_scores[(i * len(edh_scores)) // k] , edh_scores[(((i + 1) * len(edh_scores)) // k) - 1]))\n",
    "\n",
    "        # Compute minimum distance for each card and assign accordingly\n",
    "        assignments = []\n",
    "        for i in range(k):\n",
    "            cluster = []\n",
    "            assignments.append(cluster)\n",
    "\n",
    "        for index in cards_in_k.index:\n",
    "            min_distance = sys.maxsize\n",
    "            assigned_centroid_index = centroids.index(max(centroids))\n",
    "\n",
    "            for rank in centroids:\n",
    "                if abs(cards_in_k.loc[index]['edhrecRank'] - rank) < min_distance:\n",
    "                    assigned_centroid_index = centroids.index(rank)\n",
    "                    min_distance = abs(cards_in_k.loc[index]['edhrecRank'] - rank)\n",
    "            assignments[assigned_centroid_index].append(index)\n",
    "\n",
    "        # Compute new centroids based on averages of cards in cluster\n",
    "        clustered_cards = []\n",
    "        for i in range(k):\n",
    "            \n",
    "            sum = 0\n",
    "            for index in assignments[i]:\n",
    "                sum += cards_in_k.loc[index]['edhrecRank']\n",
    "            \n",
    "            centroids[i] = sum / len(assignments[i])\n",
    "            clustered_cards.append((centroids[i], assignments[i]))\n",
    "        clustered_cards = sorted(clustered_cards, key=lambda x:x[0])\n",
    "        \n",
    "        df_clusters = []\n",
    "        for cluster in clustered_cards:\n",
    "            df_clusters.append(cards_in_k[cards_in_k.index.isin(cluster[1])])\n",
    "        return df_clusters\n",
    "    \n",
    "\t#finds cards related to color identity of given commander\n",
    "    def filter_identity(self, commander_name):\n",
    "        #ease of use need to probably change this later\n",
    "        #cards = self.df_current_cards\n",
    "        cards = self.df_cards\n",
    "\n",
    "        commander_identity = set(cards[cards.name == commander_name]['colorIdentity'].iloc[0].split(', '))\n",
    "        # Get all indices of compliant cards\n",
    "        sum = 0\n",
    "        indices = []\n",
    "\n",
    "        for row in cards.index:\n",
    "            if type(cards.loc[row]['colorIdentity']) is float:\n",
    "                identity = set()\n",
    "            else:\n",
    "                identity = set(cards.loc[row]['colorIdentity'].split(', '))\n",
    "            if identity <= commander_identity:\n",
    "                indices.append(row)\n",
    "                sum += 1\n",
    "\n",
    "        valid_cards = cards[cards.index.isin(indices)]\n",
    "        return valid_cards\n",
    "\t\n",
    "\t\n",
    "    def extract_text_perms(self, card):\n",
    "        # If any ability in the catalyst triggers an ability in the reagent\n",
    "        # append the pair of indices to the edge list\n",
    "        rules = card['text'].replace('\\\\n', ' ')\n",
    "        # For each rule, split each word and find all combinations of rules text in order.\n",
    "        rule_phrases = []\n",
    "        rule_components = rules.lower().strip().replace(',', '').replace('.', '').replace(':', '').split(' ')\n",
    "\n",
    "        # For each word in parsed phrase, join next j words until end of phrase\n",
    "        for i in range(len(rule_components)):\n",
    "            for j in range(i + 1, len(rule_components) + 1):\n",
    "                rule_phrases.append(\" \".join(rule_components[i:j]))\n",
    "\n",
    "        return rule_phrases\n",
    "    \n",
    "    #card a and b use card indices not actual card values\n",
    "    def get_similarity(self, card_a, card_b):\n",
    "        # print(set(rule_phrases[card_a]))\n",
    "        return len(set(self.rule_phrases[card_a]).intersection(set(self.rule_phrases[card_b]))) / len(self.rule_phrases[card_b])\n",
    "    \n",
    "\n",
    "    # Take a list of dataframes containing cards clustered based \n",
    "    # on EDHRec rank. Starting with the most competitive cards, \n",
    "    # perform modified Apriori until the threshold of 63 cards\n",
    "    # is met. The remaining 37 cards will be basic lands\n",
    "    def apriori(self, commander_name, clusters, cards):    \n",
    "\n",
    "        # Iterate over each cluster until length requirement is met\n",
    "        # When out of unique cards in cluster, move to next\n",
    "        # Select the single candidate with the highest average support \n",
    "        # among all cards in current deck, then continue\n",
    "        cluster_pos = 0\n",
    "        # commander_index = cards[cards.name == commander_name].index[0]\n",
    "        # commander_similarity = \n",
    "        current_deck = [cards[cards.name == commander_name].index[0]]\n",
    "        sim_card = [cards[cards.name == commander_name].index[0]]\n",
    "        similarities = [1]\n",
    "        while cluster_pos < len(clusters) and len(current_deck) < 63:\n",
    "            # Compute similarity of a given card to each card in list\n",
    "            # Grab given card\n",
    "            for card in current_deck[:(len(current_deck) // 50) + 1]:\n",
    "                # Get average similarity across list?\n",
    "                max_similarity = -1\n",
    "                max_index_a = sys.maxsize\n",
    "                max_index_b = sys.maxsize\n",
    "                for index in clusters[cluster_pos].index:\n",
    "\n",
    "                    # get similarity between current card and each card already in deck\n",
    "                    card_similarity = self.get_similarity(card, index)\n",
    "                    if card_similarity > max_similarity and index not in current_deck:\n",
    "                        # print(card_similarity)\n",
    "                        max_similarity = card_similarity \n",
    "                        max_index_a = card\n",
    "                        max_index_b = index\n",
    "                # Append support with max indices\n",
    "                # Compute confidence by stringing together a pair \n",
    "                # with the card containing next highest support value, \n",
    "                # then compute standard support\n",
    "                \n",
    "            if len(current_deck) > 63:\n",
    "                break\n",
    "\n",
    "            sim_card.append(max_index_a)\n",
    "            current_deck.append(max_index_b)\n",
    "            similarities.append(max_similarity)\n",
    "                # print(len(current_deck))\n",
    "            if max_index_b == clusters[cluster_pos].index[-1]:\n",
    "                cluster_pos += 1\n",
    "        # print(max(candidate_cards, key=lambda item: item[0]), cards.loc[max(candidate_cards, key=lambda item: item[0])[1]])\n",
    "\n",
    "        rules = []\n",
    "        for i in range(len(current_deck)):\n",
    "            rules.append((sim_card[i], current_deck[i], similarities[i], cards.loc[current_deck[i]]['edhrecRank']))\n",
    "\n",
    "        rules_2 = sorted(rules, key=lambda x:x[3])\n",
    "\n",
    "        # Using rules of size 2, generate rules of size 3 and calculate support (similarity) and confidence\n",
    "        \n",
    "        rules = []\n",
    "        for card in current_deck:\n",
    "            max_similarity = -1\n",
    "            max_index_a = sys.maxsize\n",
    "            max_index_b = sys.maxsize\n",
    "            for rule in rules_2:\t\n",
    "                # Get max similarity of card to either card in rule\n",
    "                card_similarity = self.get_similarity(rule[1], card)\n",
    "                if card_similarity > max_similarity:\n",
    "                    # print(card_similarity)\n",
    "                    max_similarity = card_similarity \n",
    "                    max_index_a = rule[0]\n",
    "                    max_index_b = rule[1]\n",
    "                    rule_2_similarity = rule[2]\n",
    "            # Find denom for support by taking average similarity for included over entire deck\n",
    "            sum = 0\n",
    "            for included_card in current_deck:\n",
    "                sum += self.get_similarity(included_card, card)\n",
    "            denom = sum / len(current_deck)\n",
    "\n",
    "            # Take sum of rule similarity and max / denom\n",
    "            support_3 = (card_similarity + rule_2_similarity) / denom\n",
    "\n",
    "            # Take sum of rule similarity and max / similarity to compute confidence for 3\n",
    "            confidence = (card_similarity + rule_2_similarity) / rule_2_similarity\n",
    "            rules.append((rule[0], rule[1], card, support_3, confidence, cards.loc[card]['edhrecRank']))\n",
    "\n",
    "        rules_3 = sorted(rules, key=lambda x:x[5])\n",
    "\n",
    "        return rules_2, rules_3\n",
    "    \n",
    "    #gets related cards with given commander\n",
    "    def get_related_cards(self, commander_name, n_clusters = 6):\n",
    "        comm_cards = self.filter_identity(commander_name)\n",
    "        self.df_related_commander_cards = comm_cards\n",
    "        print(\"Total number of cards legal for deck: {}\".format(len(self.df_related_commander_cards.index)))\n",
    "\n",
    "        # Extract all rules phrases for apriori comparison\n",
    "        rule_phrases = {}\n",
    "        for i in self.df_cards.index:\n",
    "            rule_phrases[i] = self.extract_text_perms(self.df_cards.loc[i])\n",
    "        self.rule_phrases = rule_phrases\n",
    "\n",
    "\n",
    "        # Perform K-Means clustering for k clusters on cards\n",
    "        clusters = self.k_means(n_clusters, comm_cards)\n",
    "        # Print length of each cluster\n",
    "        for i in range(len(clusters)):\n",
    "            print(\"Number of cards in cluster {}: {}\".format(i, len(clusters[i])))\n",
    "\n",
    "        # Generate rules of length 2 for deck\n",
    "        #rules_2 is tuple with card in deck, recommended card, similarity score, edhrec\n",
    "        rules_2, rules_3 = self.apriori(commander_name, clusters, comm_cards)\n",
    "\n",
    "        #sorts rules 2 in descending based on similarity score\n",
    "        rules_2 = sorted(rules_2, key = lambda x:x[2], reverse=True)\n",
    "\n",
    "        #slices dataframe into related cards df and saves it to class\n",
    "        rules_2 = np.array(rules_2)\n",
    "        sim_card_indices = rules_2[:, 1]\n",
    "        related_cards = self.df_current_cards.loc[sim_card_indices, :]\n",
    "        #adds siim score to the dataframe\n",
    "        related_cards['sim_score'] = rules_2[:, 2]\n",
    "        #saves related cards to class\n",
    "        self.df_related_cards = related_cards\n",
    "\n",
    "        return related_cards\n",
    "    \n",
    "    #trains and sets the linear regression model\n",
    "    def train_linear_model(self):\n",
    "        model = SimpleLinearRegression()\n",
    "        #grabs edhrec and sim scores of related cards and trains the mdoel on them\n",
    "        df_edhrec = np.array(self.df_related_cards['edhrecRank'].tolist())\n",
    "        df_sim_scores = np.array(self.df_related_cards['sim_score'].tolist())\n",
    "        \n",
    "        df_edhrec = df_edhrec[1:]\n",
    "        df_sim_scores = df_sim_scores[1:]\n",
    "\n",
    "\n",
    "        model.fit(df_sim_scores, df_edhrec)\n",
    "\n",
    "        self.linear_model = model\n",
    "        return model\n",
    "\n",
    "        \n",
    "    #computes the upcomming recommended cards\n",
    "    #also sets the upcomming cards to the class\n",
    "    def compute_upcoming_recommendations(self, commander_name, max_cards = 10):\n",
    "        #gets similarity score of upcomming cards to commander\n",
    "        current_deck = [self.df_cards[self.df_cards.name == commander_name].index[0]]\n",
    "        sim_card = [self.df_cards[self.df_cards.name == commander_name].index[0]]\n",
    "        similarities = [1]\n",
    "        while len(current_deck) < 63:\n",
    "            for card_a in current_deck[:(len(current_deck) // 50) + 1]:\n",
    "                # Get average similarity across list?\n",
    "                max_similarity = -1\n",
    "                max_index_a = sys.maxsize\n",
    "                max_index_b = sys.maxsize\n",
    "                for index, card_b in self.df_upcoming_cards.iterrows():\n",
    "                    card_similarity = self.get_similarity(card_a, index)\n",
    "                    if card_similarity > max_similarity and index not in current_deck:\n",
    "                        # print(card_similarity)\n",
    "                        max_similarity = card_similarity \n",
    "                        max_index_a = card_a\n",
    "                        max_index_b = index\n",
    "                # Append support with max indices\n",
    "                # Compute confidence by stringing together a pair \n",
    "                # with the card containing next highest support value, \n",
    "                # then compute standard support\n",
    "\t\t\t\n",
    "            if len(current_deck) > 63:\n",
    "                break\n",
    "            sim_card.append(max_index_a)\n",
    "            current_deck.append(max_index_b)\n",
    "            similarities.append(max_similarity)\n",
    "\n",
    "        rules = []\n",
    "        for i in range(len(current_deck)):\n",
    "            rules.append((sim_card[i], current_deck[i], similarities[i], self.df_cards.loc[current_deck[i]]['edhrecRank']))\n",
    "\n",
    "        #sorts rules based on similarity and removes commander from it\n",
    "        rules = sorted(rules, key = lambda x:x[2], reverse=True)\n",
    "        rules = rules[1:]\n",
    "\n",
    "        #slices sorted indices\n",
    "        upcoming_indices = np.array([x[1] for x in rules])\n",
    "\n",
    "        #trains linear model for edhrec prediction\n",
    "        lnr_model = self.train_linear_model()\n",
    "\n",
    "        #adds associated card data in order to a list of tuples\n",
    "        upcoming_cards_data = []\n",
    "        #list goes: index, card name, colorIdentity, types, text, similarity score, edhrecActual, edhrecPrediction\n",
    "        counter = 0\n",
    "        for comm_index, card_index, sim_score, edhrec in rules:\n",
    "            row = self.df_upcoming_cards.loc[card_index]\n",
    "            #print(row['name'])\n",
    "\n",
    "            predicted_edhrec = lnr_model.predict(sim_score)\n",
    "            #print(f'predicted edhrec: {edhrec}')\n",
    "            #print(f'actual: {predicted_edhrec}\\n')\n",
    "            upcoming_cards_data.append((card_index, row['name'], row['manaCost'], row['types'], row['text'], sim_score, row['edhrecRank'], predicted_edhrec))\n",
    "            counter = counter + 1\n",
    "            if counter > max_cards:\n",
    "                break\n",
    "        self.upcoming_cards_data = upcoming_cards_data\n",
    "        return upcoming_cards_data\n",
    "    \n",
    "    #gets upcomming card names for gui\n",
    "    def get_upcoming_card_names(self):\n",
    "        cardnames = [row[1] for row in self.upcoming_cards_data]\n",
    "        return {'cardnames': cardnames}\n",
    "    \n",
    "    #gets related card names for gui\n",
    "    def get_related_card_names(self):\n",
    "        cardnames = self.df_related_cards['name'].tolist()\n",
    "        return {'cardnames': cardnames}\n",
    "    \n",
    "    def get_upcoming_card_data(self, cardname):\n",
    "        #fixes nans\n",
    "        updated_data = [\n",
    "            tuple('manaCost not found' if (isinstance(x, float) and math.isnan(x)) else x for x in row)\n",
    "            for row in self.upcoming_cards_data]\n",
    "        df_cards = pd.DataFrame(updated_data)\n",
    "        df_cards.columns = ['card_index', 'name', 'manaCost', 'types', 'text', 'sim_score', 'edhrecRank', 'edhrecRank_prediction']\n",
    "\n",
    "        row = df_cards[df_cards['name'] == cardname].iloc[0]\n",
    "\n",
    "        card_text = row['text']\n",
    "        card_text = card_text.replace('\\\\n', '- ')\n",
    "\n",
    "        card = {\n",
    "            'cardname': cardname,\n",
    "            'types': row['types'],\n",
    "            'text': card_text,\n",
    "            'manaCost': row['manaCost'],\n",
    "            'cardtext': card_text,\n",
    "            'edhrec': row['edhrecRank'],\n",
    "\n",
    "            'edhrec_predicted': row['edhrecRank_prediction'],\n",
    "            'sim_score': row['sim_score']\n",
    "            } \n",
    "\n",
    "        return card\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cards legal for deck: 11598\n",
      "Number of cards in cluster 0: 1601\n",
      "Number of cards in cluster 1: 2386\n",
      "Number of cards in cluster 2: 2362\n",
      "Number of cards in cluster 3: 1564\n",
      "Number of cards in cluster 4: 1719\n",
      "Number of cards in cluster 5: 1966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cardnames': [\"Yuriko, the Tiger's Shadow\",\n",
       "  'Ingenious Infiltrator',\n",
       "  'Seafloor Oracle',\n",
       "  'Deliberate',\n",
       "  'Dark Confidant',\n",
       "  'Research Thief',\n",
       "  'Silver-Fur Master',\n",
       "  'Throat Slitter',\n",
       "  'Ad Nauseam',\n",
       "  'Demonic Tutor',\n",
       "  'Diabolic Tutor',\n",
       "  'Ninja of the Deep Hours',\n",
       "  'Necropolis Regent',\n",
       "  'Greed',\n",
       "  'Keep Watch',\n",
       "  'Skyscanner',\n",
       "  'Mist-Syndicate Naga',\n",
       "  'Marauding Blight-Priest',\n",
       "  'Vedalken Archmage',\n",
       "  'Coastal Piracy',\n",
       "  'Thought Scour',\n",
       "  'Peek',\n",
       "  'Temple Bell',\n",
       "  'Mistblade Shinobi',\n",
       "  'Exquisite Blood',\n",
       "  'No Mercy',\n",
       "  'Walking Atlas',\n",
       "  'Entomb',\n",
       "  'Quick Study',\n",
       "  'Secrets of the Dead',\n",
       "  'Merfolk Looter',\n",
       "  'Mind Spring',\n",
       "  'Thousand-Faced Shadow',\n",
       "  'Curiosity Crafter',\n",
       "  'Fallen Shinobi',\n",
       "  'Amulet of Vigor',\n",
       "  'Spawning Kraken',\n",
       "  'Quicksilver Amulet',\n",
       "  'Grim Tutor',\n",
       "  'Unmarked Grave',\n",
       "  'Moon-Circuit Hacker',\n",
       "  'Dramatic Reversal',\n",
       "  'Crucible of Worlds',\n",
       "  'Galerider Sliver',\n",
       "  'Birthday Escape',\n",
       "  'Exhume',\n",
       "  'Silent-Blade Oni',\n",
       "  'Throne of the God-Pharaoh',\n",
       "  'Reassembling Skeleton',\n",
       "  'Altar of the Brood',\n",
       "  \"Liliana's Caress\",\n",
       "  'Phyrexian Delver',\n",
       "  'Opt',\n",
       "  'Serum Visions',\n",
       "  'Prosperity',\n",
       "  'Azami, Lady of Scrolls',\n",
       "  'Vision Skeins',\n",
       "  \"Sakashima's Student\",\n",
       "  'Long-Term Plans',\n",
       "  'Megrim',\n",
       "  'Ink-Eyes, Servant of Oni',\n",
       "  'One with the Machine',\n",
       "  'Psychic Corrosion']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtg = MTGProject()\n",
    "commander_name = 'Grey Knight Paragon'\n",
    "commander_name = \"Yuriko, the Tiger's Shadow\"\n",
    "upcoming_card_name = \"Shroudstomper\"\n",
    "related_cards = mtg.get_related_cards(commander_name)\n",
    "#related_cards\n",
    "#t, t2 = mtg.compute_upcoming_recommendations(commander_name)\n",
    "mtg.compute_upcoming_recommendations(commander_name)\n",
    "mtg.get_upcoming_card_names()\n",
    "mtg.get_related_card_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
